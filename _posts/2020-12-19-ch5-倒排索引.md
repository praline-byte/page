---
layout: post
title: 手摸手搞搜索（五）—— 倒排索引
categories: 搜索引擎
description: 
keywords: 搜索引擎 倒排索引 
---

“春天来了，万物复苏，又到了动物们繁殖的季节，山林的空气中弥漫着荷尔蒙的气息！”

假如我们要检索的数据是上面这句话，检索词是**"复苏"**，按照之前架构中已经实现的部分，该怎么做呢？

# 部分匹配的高效

经过上一章的演进，可以明确当前的搜索架构支持**精确匹配**和**前缀匹配**，但是当前的业务背景，显然无法直接利用这两种模式。

解决这个问题，我们可以回想一下在第一章中说过"搜索的本质其实就是利用存储空间，有效的组织数据，来实现快速检索"，在第二章中又介绍了"几种常见的索引结构"，
所以看来我们需要一种可以高效解决部分匹配的索引结构。

**倒排表**

我们为每个待检索的内容指定唯一编号，来减少存储空间比如

> 1 -> 春天来了，万物复苏，又到了动物们繁殖的季节，山林的空气中弥漫着荷尔蒙的气息！
>
> 2 -> 真正的勇士敢于直面惨淡的人生，敢于正视淋漓的鲜血
>
> 3 -> xxx

这种方式称为**正排表**，也即根据唯一编号可以获得整个文档信息（文档在搜索引擎中意为一条完整的数据记录，之后的内容将统一使用文档表示一条记录）。

因为要进行**部分**匹配，所以不得不对原始内容进行拆分。

现在将 “春天来了，万物复苏，又到了动物们繁殖的季节，山林的空气中弥漫着荷尔蒙的气息！” 进行拆分成词/字，并依据某种规则过滤掉无用的，不需要检索的词/字。

![](/images/posts/手摸手搞搜索_images/索引分析1.png)

假设经历过某种索引分析之后，由原始内容得到了三个词**春天**，**复苏**和**繁殖**，表示由这三个词，就可以代表这个文档表达的内容。

“春天来了，万物复苏，又到了动物们繁殖的季节，山林的空气中弥漫着荷尔蒙的气息！” -->  **春天/复苏/繁殖**

因为使用编号 1 代替原文节省空间，也即可以表示：1 -->  春天/复苏/繁殖，

又因为我们要用检索词（比如复苏）来检索文档，所以存储到搜索引擎中应当是，春天/复苏/繁殖 --> 1

也就是：

| Term | ID | 
| :-------: | :------: | 
| 春天 | 1 | 
| 复苏 | 1 | 
| 繁殖 | 1 | 

这就是倒排表，或者称为倒排索引。

这样在查询的时候，可以利用**精确匹配**快速找到对应的 ID，然后根据 ID 获取到完整的文档信息啦！

# Token 和 Term 的关系

可以知道在构建倒排索引的过程中，会对原始内容进行拆分等处理，很多资料在解释这个过程时，会混淆 Token 和 Term。

**那 Token 和 Term 具体代表是什么呢？**

放到例子中就很容易解释。

我们对原始内容 **“春天来了，万物复苏，又到了动物们繁殖的季节，山林的空气中弥漫着荷尔蒙的气息！”**，

拆分成词/字的后的 **"春天/来了/..."** 就是 Term，关键字，也是检索时的最小单位。

而拆词后的**"春天/来了/..."**，相对于原文，有很多关键信息，比如**"春天"**这个 Term 在原文中第几处出现，出现的次数是多少等等，这些信息的总成，就是 Token，也是索引时的最小单位。

如果在工程代码中定义，应该时这样的：

```
// Token 是搜索引擎中的一等公民，是我们用以索引的最小单位
type Token struct {

	// 表示 Token 首字符在原字段中的开始位置
	Start int `json:"start"`

	// 表示 Token 尾字符在原字段中的结束位置
	End int `json:"end"`

	// token 的实际值
	Term []byte `json:"term"`

	// 整个 token 在原字段中的位置
	Position int `json:"position"`
}
```

# N-gram 的实现

对于如何拆词不是我们的重点，对“春天来了，万物复苏，又到了动物们繁殖的季节，山林的空气中弥漫着荷尔蒙的气息！”这么长的原文进行处理，也蛮复杂，因为还设计很多停用词的逻辑。

为了简化理解，故事继续进行，我们继续沿用上一章中最后遗留的问题。

**如何通过搜索"咬金"查找"程咬金"**

经过这章的学习，知道部分匹配可以通过建立倒排索引的方式解决，对内容进行拆分，而对于短文本尤其时人名时，比较好用的方式可以使用 **N-gram**

N-gram 的原理很简单：

比如 1-gram 时，"程咬金" 可以转化为 "程"，"咬"，"金"

比如 2-gram 时，"程咬金" 可以转化为 "程咬"，"咬金"

比如 3-gram 时，"程咬金" 可以转化为 "程咬金"

假设这里使用 2-gram，那么对"程咬金"建立倒排索引的结果就为

| Term | Name | 
| :-------: | :------: | 
| 程咬 | 程咬金 | 
| 咬金 | 程咬金 | 

这样就可以通过精确匹配，搜索"咬金"查找到"程咬金"（利用唯一编号代替文档，这里简化理解，直接使用了 Name）

给出代码实现

```
// 构建 2-gram
func Build2Gram(input string) []string {
	rv := make([]string, 0, len(input))
	runeCount := utf8.RuneCount([]byte(input))
	runes := bytes.Runes([]byte(input))
	ngramSize := 2
	for i := 0; i < runeCount; i++ {
		if i+ngramSize <= runeCount {
			rv = append(rv, string(runes[i : i+ngramSize]))
		}
	}
	return rv
}
```
>关于计算机中如何表示字符，推荐 https://juejin.im/post/6844903743524175879

构建 1,2,...,N-gram 的实现，可以在 [https://github.com/praline-byte/search-engine](https://github.com/praline-byte/search-engine) 获取。

```
// 构建 n-gram
func BuildNGram(input string, minLen, maxLen int) []string {
    ···
}
```

运行 ngram_test.go 得到
```
    TestBuildNGram: ngram_test.go:7: 2-gram:
    TestBuildNGram: ngram_test.go:8: [程咬 咬金]
    TestBuildNGram: ngram_test.go:9: n-gram:
    TestBuildNGram: ngram_test.go:10: [程 程咬 咬 咬金 金]
```

# 小结

本章是搜索引擎的理论基础，介绍了倒排索引，定义清楚 Token 和 Term，并实现一种常见的 TokenFilter——Ngram。

> TokenFilter 是什么？见下一章

站在更高的角度，在搜索引擎中，对需要检索的数据是如何进行处理的呢？

下一章中，我们将继续演进搜索引擎的**索引分析部分**，搭建索引分析层。






